{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bebd359e-e516-4819-a572-8efe1a917468",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0adfe679-dcaf-41d6-8e12-98d9d7b56f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "definition done\n"
     ]
    }
   ],
   "source": [
    "def convert_to_sharegpt(src_file,tgt_file):\n",
    "    with open(src_file,mode=\"r\") as src,open(tgt_file,mode=\"w\") as tgt:\n",
    "        conversations = json.load(src)\n",
    "        target_list = []\n",
    "        print(\"converting into sharegpt format\")\n",
    "        \n",
    "        for id,conversation in tqdm(conversations.items()):\n",
    "            self_report = {\"from\":\"user\",\n",
    "                           \"value\":conversation[\"self_report\"]}\n",
    "            previous_sentence = self_report\n",
    "            # if previous speaker and current speaker are same, merge the sentences\n",
    "            \n",
    "            conv = {\n",
    "                # \"id\": id,\n",
    "                \"conversations\":[],\n",
    "                \"system\":\"你是一个智能医疗诊断助手，请根据用户输入的症状描述，解答用户的问题或给出医学建议，推动对话直至得出医学诊断结论，如果信息不足，请要求用户提供必要的信息。\",\n",
    "            }\n",
    "            conv[\"conversations\"].append(previous_sentence)\n",
    "            \n",
    "            for item in  conversation[\"dialogue\"]:\n",
    "                role = item[\"speaker\"]\n",
    "                value = item[\"sentence\"]\n",
    "                if (\"user\" if role==\"患者\" else \"assistant\") == previous_sentence[\"from\"]:\n",
    "                    if previous_sentence[\"value\"].endswith(tuple([\"，\",\"。\",\"？\",\"！\",\"~\",\"；\",\"、\"])):\n",
    "                        previous_sentence[\"value\"] = previous_sentence[\"value\"]+\" \"+value\n",
    "                    else:\n",
    "                        previous_sentence[\"value\"] = previous_sentence[\"value\"]+\"。\"+value\n",
    "                    # print(\"current role == previous role:\"+ role,\"merged value=\"+previous_sentence[\"value\"])\n",
    "                    conv[\"conversations\"][-1] = previous_sentence\n",
    "                else:\n",
    "                    sentence =  { \"from\": \"user\" if role==\"患者\" else \"assistant\",\n",
    "                      \"value\": value}\n",
    "                    conv[\"conversations\"].append(sentence)\n",
    "                    previous_sentence = sentence\n",
    "            #the last response should be by assistant,otherwise, append one sentence\n",
    "            if(conv[\"conversations\"][-1][\"from\"]==\"user\"):\n",
    "                conv[\"conversations\"].append({\n",
    "                    \"from\":\"assistant\",\n",
    "                    \"value\":\"祝您早日康复，再见\"\n",
    "                })\n",
    "            target_list.append(conv)\n",
    "            # print(target_list)\n",
    "            \n",
    "            \n",
    "        print(\"print into target json file as training materials\")\n",
    "        json.dump(obj=target_list,fp=tgt,ensure_ascii=False,indent=4)\n",
    "        print(f\"writing to {tgt} completed\")\n",
    "    \n",
    "print(\"definition done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cfd31d3-1780-4828-8ef4-be4cc09d0b67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting into sharegpt format\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2472/2472 [00:00<00:00, 38243.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print into target json file as training materials\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing to <_io.TextIOWrapper name='./NER/IMCS-V2_train_conversation.json' mode='w' encoding='UTF-8'> completed\n",
      "converting into sharegpt format\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 833/833 [00:00<00:00, 50994.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print into target json file as training materials\n",
      "writing to <_io.TextIOWrapper name='./NER/IMCS-V2_dev_conversation.json' mode='w' encoding='UTF-8'> completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "convert_to_sharegpt(src_file=\"./NER/IMCS-V2_train.json\",tgt_file=\"./NER/IMCS-V2_train_conversation.json\")\n",
    "convert_to_sharegpt(src_file=\"./NER/IMCS-V2_dev.json\",tgt_file=\"./NER/IMCS-V2_dev_conversation.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a052e02b-fd27-4d0b-a4a7-418eff7ad6b3",
   "metadata": {},
   "source": [
    "### 加入dataset_info.json\n",
    "```json\n",
    "  \"IMCS-V2_train_conversation\": {\n",
    "    \"file_name\": \"IMCS-V2_train_conversation.json\",\n",
    "    \"formatting\": \"sharegpt\",\n",
    "    \"columns\": {\n",
    "      \"messages\": \"conversations\"\n",
    "    },\n",
    "    \"tags\": {\n",
    "      \"role_tag\": \"from\",\n",
    "      \"content_tag\": \"value\",\n",
    "      \"user_tag\": \"user\",\n",
    "      \"assistant_tag\": \"assistant\"\n",
    "    }\n",
    "  },\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b91e44-b7b4-448f-957f-a7d3be7883ed",
   "metadata": {},
   "source": [
    "### 测试结果 0.5B三轮全参数训练的结果\n",
    "```\n",
    "[INFO|2025-01-08 16:30:30] llamafactory.model.model_utils.attention:157 >> Using torch SDPA for faster training and inference.\n",
    "[INFO|2025-01-08 16:30:30] llamafactory.model.loader:157 >> all params: 494,032,768\n",
    "\n",
    "        Average: 40.83                                                                                                                                \n",
    "           STEM: 35.165%|██████████████████████▍                                                                    | 52/211 [00:00<00:00, 256.96it/s]\n",
    "Social Sciences: 42.03\n",
    "     Humanities: 41.46\n",
    "          Other: 43.71\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cb9e0f-15b0-4e60-980f-dc272c98c709",
   "metadata": {},
   "source": [
    "### 测试结果 7B十二轮LoRA训练结果\n",
    "```\n",
    "        Average: 77.59                                                                                                                                                                 \n",
    "           STEM: 71.51\n",
    "Social Sciences: 78.04\n",
    "     Humanities: 80.07\n",
    "          Other: 80.17\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd008eea-729d-40f9-bf8f-afb0e454d4cc",
   "metadata": {},
   "source": [
    "### 测试结果 7B预训练模型\n",
    "```\n",
    "        Average: 80.20                                                                                                                                \n",
    "           STEM: 73.25\n",
    "Social Sciences: 80.28\n",
    "     Humanities: 83.29\n",
    "          Other: 83.51\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
